# Single-Turn Continuous Agent Architecture

## Overview
This document outlines a methodology for solving complex algorithmic problems using a single Large Language Model (LLM) acting as a continuous, state-aware agent.

The core philosophy is that "State" and "Memory" should not be maintained by the LLM's context window (which degrades over turns), but rather by an external **Python Executive** that manages a structured "Identity Snapshot" re-injected into the LLM at every single turn.

## Core Concept: The "Memento" Pattern
The Agent is re-instantiated at every step. It has no "memory" of previous chat turns. Instead, it receives a **fresh prompt** containing three distinct layers of context that reconstruct its "Self" and "Situation":

1.  **Layer A: Constitution (Identity)** - Immutable rules and goals.
2.  **Layer B: State (Working Memory)** - Current progress, hypotheses, and next objectives.
3.  **Layer C: Evidence (Reality)** - Hard facts, test results, and execution logs.

## The Role of the Python Executive
Measurements, file storage, and "memory selection" are handled by a Python runtime system, not the LLM. The Python Executive:
-   **Executes** code generated by the LLM.
-   **Validates** results against test cases (Oracle/Partial Oracle).
-   **Summarizes** findings into the Evidence Layer.
-   **Updates** the State Layer based on the LLM's decisions and execution outcomes.
-   **Constructs** the next Prompt.

## File Structure
- `LAYERS.md`: Detailed schema and definition of the three context layers.
- `UPDATE_LOGIC.md`: The algorithmic process for updating layers between turns.
- `PROMPT_TEMPLATE.md`: The structure of the single-turn prompt.
